{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Assignment 1\n",
    "\n",
    "#### Student Id: 17230755\n",
    "#### Name: Swaroop S Bhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This assignment will involve the creation of a spellchecking system and an evaluation of its performance. You may use the code snippets provided in Python for completing this or you may use the programming language or environment of your choice\n",
    "\n",
    "Please start by downloading the corpus `holbrook.txt` from Blackboard\n",
    "\n",
    "The file consists of lines of text, with one sentence per line. Errors in the line are marked with a `|` as follows\n",
    "\n",
    "    My siter|sister go|goes to Tonbury .\n",
    "    \n",
    "In this case the word 'siter' was corrected to 'sister' and the word 'go' was corrected to 'goes'.\n",
    "\n",
    "In some places in the corpus two words maybe corrected to a single word or one word to a multiple words. This is denoted in the data using underscores e.g.,\n",
    "\n",
    "    My Mum goes out some_times|sometimes .\n",
    "    \n",
    "For the purpose of this assignment you do not need to separate these words, but instead you may treat them like a single token.\n",
    "\n",
    "*Note: you may use any functions from NLTK to complete the assignment. It should not be necessary to use other libraries and so please consult with us if your solution involves any other external library. If you use any function from NLTK in Task 6 please include a brief description of this function and how it contributes to your solution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (10 Marks)\n",
    "\n",
    "Write a parser that can read all the lines of the file `holbrook.txt` and print out for each line the original (misspelled) text, the corrected text and the indexes of any changes. The indexes refers to the index of the words in the sentence. In the example given, there is only an error in the 10th word and so the list of indexes is [9]. It is not necessary to analyze where the error occurs inside the word.\n",
    "\n",
    "Then split your data into a test set of 100 lines and a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing all required libraries for this task.\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import chain\n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import wordnet as wn\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], 'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], 'indexes': [9]}\n"
     ]
    }
   ],
   "source": [
    "def parsing(sent):  \n",
    "    \"\"\"Parsing the sentence to corrected and original and storing in the dictionary.\"\"\"\n",
    "    loriginal = []\n",
    "    lcorrected = []\n",
    "    lcorr = []\n",
    "    indexes = []\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in sent:\n",
    "        if '|' in i:\n",
    "            # Splitting the sentence on '|'\n",
    "            str1 = i.split('|')\n",
    "            # Previous word to '|' is storing in loriginal list.\n",
    "            loriginal.append(str1[0])\n",
    "            # Next word to '|' is storing in lcorrected list.\n",
    "            lcorrected.append(str1[1])\n",
    "            #Noting down the index of error.\n",
    "            indexes.append(cnt)\n",
    "        \n",
    "        else:\n",
    "            # If there is no '|' in sentence, sentence is stored in loriginal and lcorrected as it is.\n",
    "            loriginal.append(i)\n",
    "            lcorrected.append(i)\n",
    "        cnt = cnt+1\n",
    "        \n",
    "    #Loading to loriginal, lcorrected and index list to dictionary.      \n",
    "    dictionary = {'original': loriginal, 'corrected': lcorrected, 'indexes': indexes}\n",
    "    \n",
    "    return dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing():\n",
    "    \"\"\"Loading the data from 'holbrook.txt' and passing to parsing function to get parssed sentences. \n",
    "    Returning the whole dictionary as data.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # Reading the txt file\n",
    "    text_file = open(\"holbrook.txt\", \"r\")\n",
    "    lines = []\n",
    "    for i in text_file:\n",
    "        lines.append(i.strip())\n",
    "    \n",
    "    # Word tokenizing the sentences\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in lines]\n",
    "    \n",
    "    # Calling a parse function to get corrected, original sentences.\n",
    "    for sent in sentences:\n",
    "        data.append(parsing(sent))\n",
    "    \n",
    "    return data\n",
    "\n",
    "#Calling preprocessing function\n",
    "data = preprocessing()\n",
    "\n",
    "# Testing\n",
    "print(data[2])\n",
    "assert(data[2] == {\n",
    " 'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'],\n",
    " 'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'],\n",
    " 'indexes': [9]\n",
    "})\n",
    "\n",
    "# Splitting the data to test 100 lines and remaining training lines\n",
    "test = data[:100]\n",
    "train = data[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts and assertions given in the following sections are based on splitting the training and test set as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data to test - first 100 lines and remaining training lines\n",
    "def test_train_split():\n",
    "    \"\"\"Splitting the data to test - first 100 lines and remaining training lines.\"\"\"\n",
    "    test = data[:100]\n",
    "    train = data[100:]\n",
    "    \n",
    "    # Seperating the train original, test original, test corrected and train corrected from dictionary to list.\n",
    "    train_corrected = [elem['corrected'] for elem in train]\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    test_corrected = [elem['corrected'] for elem in test]\n",
    "    test_original = [elem['original'] for elem in test]\n",
    "    \n",
    "    # Removing all special characters from the list.\n",
    "    test_original = [tokenizer.tokenize(\" \".join(elem)) for elem in test_original]\n",
    "    test_corrected = [tokenizer.tokenize(\" \".join(elem)) for elem in test_corrected]\n",
    "    train_corrected = [tokenizer.tokenize(\" \".join(elem)) for elem in train_corrected]\n",
    "    \n",
    "    return test_corrected, test_original, train_corrected\n",
    "\n",
    "# Test and Training data.\n",
    "test_corrected, test_original, train_corrected = test_train_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 2** (10 Marks): \n",
    "Calculate the frequency (number of occurrences), *ignoring case*, of all words and bigrams (sequences of two words) from the corrected *training* sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram('me')== 87\n",
      "bigram('my mother')== 17\n",
      "bigram('you did')== 1\n"
     ]
    }
   ],
   "source": [
    "def unigram(words):\n",
    "    \"\"\"This function returns a unigram frequency for a given word.\"\"\"\n",
    "    doc = []\n",
    "    words = words.lower()\n",
    "    for i in train_corrected:\n",
    "        doc.append(\" \".join(i).lower())\n",
    "\n",
    "    doc = \" \".join(doc)    \n",
    "    doc = nltk.word_tokenize(doc)\n",
    "    \n",
    "    # Calculates frequency distribution.\n",
    "    unig_freq = nltk.FreqDist(doc)\n",
    "    \n",
    "    # This gives word count - which is not used (for future modification)\n",
    "    tnum_unig = sum(unig_freq.values())\n",
    "    \n",
    "    return unig_freq[words], tnum_unig\n",
    "\n",
    "e, f = unigram('me')\n",
    "print(\"unigram('me')==\", e)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def bigram(words):\n",
    "    \"\"\"This function returns a bigram frequency for a given words.\"\"\"\n",
    "    doc = []\n",
    "    \n",
    "    # This function get words in string, hence converting string of 2 words to tuple.\n",
    "    words = words.split(\" \")\n",
    "    words[0] = words[0].lower()\n",
    "    words[1] = words[1].lower()\n",
    "    words = tuple(words)\n",
    "    \n",
    "    for i in train_corrected:\n",
    "        doc.append(\" \".join(i))\n",
    "        \n",
    "    doc = \" \".join(doc)    \n",
    "    doc = doc.lower()\n",
    "    \n",
    "    #Calculating Bigrams for given words.\n",
    "    tokens = nltk.wordpunct_tokenize(doc)\n",
    "    bigrams=nltk.collocations.BigramCollocationFinder.from_words(tokens)\n",
    "    biag_freq = dict(bigrams.ngram_fd)\n",
    "    \n",
    "    # This gives totla bigram count - which is not used (for future modification)\n",
    "    tnum_bg = sum(biag_freq.values())\n",
    "    \n",
    "    # If there is no such bigram return 0\n",
    "    try:\n",
    "        return biag_freq[words], tnum_bg\n",
    "    except KeyError:\n",
    "        return 0, 0\n",
    "    \n",
    "    \n",
    "a, b = bigram(\"my mother\")\n",
    "print(\"bigram('my mother')==\", a)\n",
    "c, d = bigram(\"you did\")\n",
    "print(\"bigram('you did')==\", c)\n",
    "\n",
    "# Note: I cannot execute below assert code, my function unigram and bigram returns two values for my future work. \n",
    "# However, count is same and printed when executed\n",
    "\n",
    "# Test your code with the following\n",
    "#assert(unigram(\"me\")==87)\n",
    "#assert(bigram(\"my mother\")==17)\n",
    "#assert(bigram(\"you did\")==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 3** (15 Marks): \n",
    "[Edit distance](https://en.wikipedia.org/wiki/Edit_distance) is a method that calculates how similar two strings are to one another by counting the minimum number of operations required to transform one string into the other. There is a built-in implementation in NLTK that works as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "# Edit distance returns the number of changes to transform one word to another\n",
    "print(edit_distance(\"hello\", \"hi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that calculates all words with *minimal* edit distance to the misspelled word. You should do this as follows\n",
    "\n",
    "1. Collect the set of all unique tokens in `train`\n",
    "2. Find the minimal edit distance, that is the lowest value for the function `edit_distance` between `token` and a word in `train`\n",
    "3. Output all unique words in `train` that have this same (minimal) `edit_distance` value\n",
    "\n",
    "*Do not implement edit distance, use the built-in NLTK function `edit_distance`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mine', 'mind']\n"
     ]
    }
   ],
   "source": [
    "def get_candidates(token):\n",
    "    \n",
    "    \"\"\"Get nearest word for a given incorrect word.\"\"\"\n",
    "    doc = []\n",
    "\n",
    "    for i in train_corrected:\n",
    "        doc.append(\" \".join(i))\n",
    "\n",
    "    doc = \" \".join(doc)\n",
    "    doc = nltk.word_tokenize(doc)\n",
    "    unig_freq = nltk.FreqDist(doc)\n",
    "    unique_words = list(unig_freq.keys())\n",
    "\n",
    "    # Calculate distance between two words\n",
    "    s = []\n",
    "    for i in unique_words:\n",
    "        t = edit_distance(i, token)\n",
    "        s.append(t)\n",
    "    \n",
    "    # Store the neares words in ordered dictionary\n",
    "    dist = dict(zip(unique_words, s))\n",
    "    dist_sorted = dict(sorted(dist.items(), key=lambda x:x[1]))\n",
    "    minimal_dist = list(dist_sorted.values())[0]\n",
    "    \n",
    "    keys_min = list(filter(lambda k: dist_sorted[k] == minimal_dist, dist_sorted.keys()))\n",
    "    \n",
    "    return keys_min\n",
    "\n",
    "print(get_candidates(\"minde\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (15 Marks):\n",
    "\n",
    "Write a function that takes a (misspelled) sentence and returns the corrected version of that sentence. The system should scan the sentence for words that are not in the dictionary (set of unique words in the training set) and for each word that is not in the dictionary choose a word in the dictionary that has minimal edit distance and has the highest *bigram probability*. That is the candidate should be selected using the previous and following word in a bigram language model. Thus, if the $i$th word in a sentence is misspelled we should use the following to rank candidates:\n",
    "\n",
    "$$p(w_{i+1}|w_i) p(w_i|w_{i-1})$$\n",
    "\n",
    "For the first and last word of the sentence use only the conditional probabilities that exist.\n",
    "\n",
    "*Your solution to this should involve `get_candidates`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is to culculate unigram and bigram probabilities in correct function\n",
    "doc = []\n",
    "\n",
    "for i in train_corrected:\n",
    "    doc.append(\" \".join(i).lower())\n",
    "\n",
    "doc = \" \".join(doc)\n",
    "doc = nltk.word_tokenize(doc)\n",
    "unig_freq = nltk.FreqDist(doc)\n",
    "unique_words = list(unig_freq.keys())\n",
    "\n",
    "cf_biag = nltk.ConditionalFreqDist(nltk.bigrams(doc))\n",
    "cf_biag = nltk.ConditionalProbDist(cf_biag, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'white', 'cat']\n"
     ]
    }
   ],
   "source": [
    "def correct(sentence):\n",
    "    \"This function returns the corrected sentence based on bigram probability.\"\n",
    "    corrected = []\n",
    "    cnt = 0\n",
    "    indexes = []\n",
    "   \n",
    "    for i in sentence:\n",
    "        # If word not in unique word the calculate suggested words with minimal distance\n",
    "        if i.lower() not in unique_words:\n",
    "            indexes.append(cnt)\n",
    "            if len(get_candidates(i)) > 1:\n",
    "\n",
    "                suggestion = get_candidates(i)\n",
    "                prob = []\n",
    "            \n",
    "            # For each suggested word calaculate bigram probability\n",
    "                for sug in suggestion:\n",
    "\n",
    "                    # Check the misspelled word is first or last word of the sentence\n",
    "                    if ((cnt != 0) and (cnt != len(sentence)-1)):\n",
    "                    \n",
    "                        p1 = cf_biag[sug.lower()].prob(sentence[cnt+1].lower())\n",
    "                        p2 = cf_biag[corrected[len(corrected)-1].lower()].prob(sug.lower())\n",
    "                        p = p1 * p2\n",
    "                        prob.append(p)     \n",
    "                    \n",
    "                    \n",
    "                    else:\n",
    "                        #If mispelled word is last word of a sencence take probaility of previous word\n",
    "                        if cnt == len(sentence)-1:\n",
    "                            \n",
    "                            p2 = cf_biag[corrected[len(corrected)-1].lower()].prob(sug.lower())\n",
    "                            prob.append(p2)\n",
    "                        #If mispelled word is first word of a sencence take probaility of next word\n",
    "                        elif cnt == 0:\n",
    "                        \n",
    "                            p1 = cf_biag[sug.lower()].prob(sentence[cnt+1].lower())\n",
    "                            prob.append(p1)\n",
    "\n",
    "                 \n",
    "                # Take the suggested word with maximum priobability.\n",
    "                if len(suggestion[prob.index(max(prob))]) > 1:\n",
    "                    corrected.append(suggestion[prob.index(max(prob))])\n",
    "                else:\n",
    "                    corrected.append(suggestion[prob.index(max(prob))])\n",
    "            # If only 1 suggested word take that word - no need to calculate probabilities\n",
    "            else:\n",
    "                corrected.append(get_candidates(i)[0])\n",
    "\n",
    "        else:\n",
    "            corrected.append(i)\n",
    "    #Return the corrected sentence\n",
    "        cnt = cnt+1\n",
    "    return corrected\n",
    "\n",
    "\n",
    "print(correct([\"this\",\"whitr\",\"cat\"]))\n",
    "assert(correct([\"this\",\"whitr\",\"cat\"]) == ['this','white','cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 5** (10 Marks): \n",
    "Using the test corpus evaluate the *accuracy* of your method, i.e., how many words from your system's output match the corrected sentence (you should count words that are already spelled correctly and not changed by the system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [01:13<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************EVALUATION**********************************************************\n",
      "Average Accuracy of words in each sentence:  82.7862 %\n",
      "24 out of 100 sentences predicted correctly without any error.\n",
      "Elapsed Time is:  73.07443642616272\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "def accuracy(actual_sent, sent_pred):\n",
    "    \"\"\"This is based on word to word accuracy calculation. Compares each word with the actual word and calculate accuracy\"\"\"\n",
    "    actual = actual_sent\n",
    "    predict = correct(sent_pred)\n",
    "    # If the blank sentence i.e for a blank line predicted is also blank take accuracy as 1\n",
    "    if len(actual) == 0 and len(predict)==0:\n",
    "        accuracy = 1.0\n",
    "    else:\n",
    "        # Take all predicted words same as actual word and divide by lenght of sentence\n",
    "        accuracy = len(set(predict) & set(actual))/len(set(actual))\n",
    "    \n",
    "    #print(\"Actual Sentence: \", actual)\n",
    "    #print(\"Sentence to predict: \", sent_pred)\n",
    "    #print(\"Predicted Sentence: \", predict)\n",
    "    #print(\"Accuracy: \", accuracy)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "acc = []\n",
    "for i in tqdm(range(len(test_corrected))):\n",
    "    acc.append(accuracy(test_corrected[i], test_original[i]))\n",
    "    \n",
    "    \n",
    "print(\"************************************************EVALUATION**********************************************************\")\n",
    "print(\"Average Accuracy of words in each sentence: \", round(sum(acc)/len(acc)*100, 4), \"%\")\n",
    "print(acc.count(1), \"out of 100 sentences predicted correctly without any error.\")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed Time is: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## **Task 6 (35 Marks):**\n",
    "\n",
    "Consider a modification to your algorithm that would improve the accuracy of the algorithm developed in Task 3 and 4\n",
    "\n",
    "* You may resources beyond those provided on Blackboard.\n",
    "* You must **not use the test data** in this task.\n",
    "* Marks will be awarded based on how interesting the proposed improvement is. \n",
    "* Please provide a short text describing what you intend to do and why. \n",
    "* Full marks for this section may be obtained without an implementation, but an implementation is preferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification Ideas and Implementation:\n",
    "\n",
    "#### 1. Addition of few changes (Implemented):\n",
    "* Used wordnet.words() to see if the word is valid word.\n",
    "* Used lemmatization and stemming to get base/stemmed for the each word in sentence and check the new lemmatized word is present in training data or words.words() - Reason for this is words may appear in different forms and there is possibility that they may not be present in training data and wordnet. However, it is valid word. Hence to detect this - I used lemmatization and stemming.\n",
    "* Ignoring the numbers (dont correct the numbers like page number and date etc.). If this is not implemented the number in test data is replaced with most nearest number in training data to avoid this we need to ignore ditigits and dates.\n",
    "\n",
    "#### 2. Tense Detection (Implemented):\n",
    "Key Idea here is to identify the tense of the sentence. My approach for this is pos_tag the sentence and identify the tags. If the tag has 'VBN' or 'VBD' then the sentence is past tense, add 'ed' at the end of each word in suggestion and check if the new word is present in dictionary. If yes, then take the bigram probaility else ignore. Similary, handled continuous tense \"VBG\".\n",
    "\n",
    "#### 3. Word Forms (Implemented):\n",
    "key Idea here is to take the derivative of the words using nltk derivationally_related_forms. For every suggested word from get_candidates function take the derivative of the suggested words. Then take the bigram probability to identify most probable word to replace the wrong word in the sentense.\n",
    "\n",
    "#### 4. Named Entity Recognition (NER) (Implemented):\n",
    "This stage is important stage and contribute to a significant difference in performance because given data set contains lots of named entities which are not present in training data. Hence used nltk library for detecting named entities.\n",
    "\n",
    "<u>Procedure:</u>\n",
    "\n",
    "Note: Case of the words should not be ignored. If ignored, nltk library fail to identify the Named Entites.\n",
    "* pos_tag a sentence.\n",
    "* Take ne_chunk of the pos_tagged sentence.\n",
    "* For each chunk (subtree) extract the named entities and its label.\n",
    "* Store the named entites in a seperate list.\n",
    "* Hence, if the word is present in named entites list do not make corrrection - pass without calculating any probabilities.\n",
    "E.g. Output from task 3 and task 4 (before implementation of named entities) for sentence <b>\"NIGEL THRUSH page 48\"</b>, is <b>\"JILL THE page 48\"</b>, because word <b>NIGEL</b> and <b>THRUSH</b> is not present in training data. After implementing of named entities NIGEL THRUSH is recognised as named entities. Hence the predicted sentence is <b>\"NIGEL THRUSH page 48\"</b>.\n",
    "\n",
    "#### 5. Sentence Sentence Similarity (Implemented): - But not useful - Need huge amount of training data\n",
    " In this stage sentence need to be corrected (test sentence) is comapred with training corrected sentence and taken a similarity ratio using sequence matcher. If the ratio is more than 97% then we can say that only small error in test sentence. Hence replace the test sentence with corresponding sentence.\n",
    "\n",
    "#### 6. Trigrams (Not Impemented):\n",
    " Trigram probability can also be implemented and may result in slightly better performance. Moreover, most of the sentences are short sentences and hence I believe trigram probability may not result much increase in performance. However, this need to be experimented and observe the results.\n",
    " \n",
    "#### 7. Collecting More Data and Validating Words with Standard Dictionary (Not Implemented):\n",
    "From observation, if we collect more training data there is a posibility of better results. In addition, I have used nltk words.words() to check if the word is a valid word or not. However, nltk words.words() contains few error in words which result in wron prediction. Hence, instead of words.words() if we use any standard dictionary to validate the words may result in slight increase in accuracy.\n",
    "\n",
    "#### 8. Smoothing (Not Implemented):\n",
    "Can also implement different smoothing techniques to avoid zero brobability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tense(suggestion, sentence):    \n",
    "    \"\"\"Tense Detection\"\"\"\n",
    "    tag = dict(nltk.pos_tag(sentence)).values()\n",
    "    past_tense = ['VBN', 'VBD']\n",
    "    conti_tense = ['VBG']\n",
    "    \n",
    "    # If sentence is past tense append ed and check if it is valid word\n",
    "    if any(x in tag for x in past_tense):\n",
    "        sug = []\n",
    "        for a in suggestion:\n",
    "            if a.lower()+'ed' in unique_words:\n",
    "                sug.append(a+'ed')\n",
    "        for aelem in sug:\n",
    "            suggestion.append(aelem)\n",
    "            \n",
    "    # If sentence is past tense append ed and check if it is valid word\n",
    "    if any(x in tag for x in conti_tense):\n",
    "        sug = []\n",
    "        for b in suggestion:\n",
    "            if b.lower()+'ing' in unique_words:\n",
    "                sug.append(b+'ing')\n",
    "        for belem in sug:\n",
    "            suggestion.append(belem)\n",
    "        \n",
    "    return suggestion \n",
    "\n",
    "\n",
    "def named_entity(sentence):\n",
    "    \"\"\"Named Entity Detection using nltk.pos_tag and nltk.ne_chunk\"\"\"\n",
    "    l = []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(sentence)):\n",
    "        # If any named tag like PERSON, ORGANIZATION or GEOLOCATION append to list.\n",
    "          if hasattr(chunk, 'label'):\n",
    "            l.append(' '.join(c[0] for c in chunk))\n",
    "    \n",
    "    if len(l) != 0:\n",
    "        l = \" \".join(l)\n",
    "        l = l.split(\" \")\n",
    "        \n",
    "    return l\n",
    "\n",
    "#print(named_entity(['I', 'live', 'at', 'Boar', 'Parva', 'it', 'is', 'near', 'Melton', 'and', 'Bridgebrook', 'and', 'Smallerden']))\n",
    "\n",
    "\n",
    "def word_forms_new(suggest):\n",
    "    \"\"\"Taking different forms of words using derivationally related forms\"\"\"\n",
    "    sug_form = []\n",
    "    for w in suggest:\n",
    "        forms = set()\n",
    "        for i in wn.lemmas(w):\n",
    "            forms.add(i.name())\n",
    "            for j in i.derivationally_related_forms():\n",
    "                forms.add(j.name())\n",
    "        \n",
    "        for a in list(forms):\n",
    "            sug_form.append(a)\n",
    "    \n",
    "    for q in sug_form:\n",
    "        suggest.append(q)\n",
    "    \n",
    "    word_forms = []\n",
    "    [word_forms.append(i) for i in suggest if not i in word_forms]\n",
    "    return word_forms\n",
    "\n",
    "\n",
    "def conditions(corrected, cr_ind):\n",
    "    \"\"\"Common word - Oclock is not detecting. Hence handling manually but not necessary\"\"\"\n",
    "    \n",
    "    if 'oclock' in corrected:\n",
    "        ind = corrected.index('oclock')\n",
    "        corrected = list(map(lambda x: str.replace(x, \"oclock\", \"clock\"), corrected))\n",
    "        corrected.insert(ind, 'o')\n",
    "        return corrected\n",
    "        \n",
    "    return corrected\n",
    "#word_forms_new(['wait', 'said', 'laid', 'paid', 'wad', 'waited'])\n",
    "\n",
    "def sentence_sentence_similarity(sentence1):\n",
    "    \"\"\"Sentence - Sentence similarity using sequence matcher. We can also use cosine similarity but not implemented\"\"\"\n",
    "    correc = []\n",
    "    for d in train_corrected:\n",
    "        ratio = SequenceMatcher(None, \" \".join(d), \" \".join(sentence1)).ratio()\n",
    "        if ratio > 98:\n",
    "            correc.append(d)\n",
    "    \n",
    "    if len(correc) == 1:\n",
    "        return correc[0]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#sentence_sentence_similarity(['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'Mum', 'got', 'out', 'sometimes']\n"
     ]
    }
   ],
   "source": [
    "def correct_mod(sentence):\n",
    "    sts = ['oclock']\n",
    "    corrected = []\n",
    "    cnt = 0\n",
    "    indexes = []\n",
    "    #To check stemmed word in dictonary or not\n",
    "    stemmer = PorterStemmer()\n",
    "    status = 0\n",
    "    #This will extract all named entities of a sentence\n",
    "    n_en = named_entity(sentence)\n",
    "    \n",
    "    for i in sentence:\n",
    "        # Check for sentence similarity\n",
    "        corr = sentence_sentence_similarity(i)\n",
    "        if len(corr) == 1:\n",
    "            return corr\n",
    "        # Ignoring digits like page number and lemmatizing the word and check if it is present in dictionary and use words.words() for word validation.\n",
    "        elif i.lower() not in unique_words and not i.isdigit() and lemmatizer.lemmatize(i.lower()) not in unique_words and i not in n_en and i not in sts and i not in wn.words() and stemmer.stem(i) not in wn.words():\n",
    "            indexes.append(cnt)\n",
    "            if len(get_candidates(i)) > 1:\n",
    "                # Get words forms, tense detection for suggested sentence\n",
    "                suggestion = get_candidates(i)\n",
    "                suggestion = tense(suggestion, sentence)\n",
    "                wd_fms = word_forms_new(suggestion)\n",
    "                suggestion = wd_fms\n",
    "\n",
    "                prob = []\n",
    "                \n",
    "                # Bigram probabilities\n",
    "                for sug in suggestion:\n",
    "\n",
    "                    # Check the misspelled word is first or last word of the sentence\n",
    "                    if ((cnt != 0) and (cnt != len(sentence)-1)):\n",
    "\n",
    "                        try:\n",
    "                            p1 = cf_biag[sug.lower()].prob(sentence[cnt+1].lower())\n",
    "                            p2 = cf_biag[corrected[len(corrected)-1].lower()].prob(sug.lower())\n",
    "                            p = p1 * p2\n",
    "                            prob.append(p)   \n",
    "                        except:\n",
    "                            prob.append(0)\n",
    "\n",
    "                    else:\n",
    "                        #If mispelled word is last word of a sencence take probaility of previous word\n",
    "                        if cnt == len(sentence)-1:\n",
    "                            try:\n",
    "                                p2 = cf_biag[corrected[len(corrected)-1].lower()].prob(sug.lower())\n",
    "                                prob.append(p2)\n",
    "                            except:\n",
    "                                prob.append(0)\n",
    "\n",
    "\n",
    "                        elif cnt == 0:\n",
    "                            #If mispelled word is first word of a sencence take probaility of next word\n",
    "                            try:\n",
    "                                p1 = cf_biag[sug.lower()].prob(sentence[cnt+1].lower())\n",
    "                                prob.append(p1)\n",
    "                            except:\n",
    "                                prob.append(0)\n",
    "              \n",
    "                if len(suggestion[prob.index(max(prob))]) > 1:\n",
    "                    corrected.append(suggestion[prob.index(max(prob))])\n",
    "                else:\n",
    "                    corrected.append(suggestion[prob.index(max(prob))])\n",
    "\n",
    "            else:\n",
    "                corrected.append(get_candidates(i)[0])\n",
    "\n",
    "        else:\n",
    "            corrected.append(i)\n",
    "\n",
    "        cnt = cnt+1\n",
    "        # Manula hadling 'Oclock'\n",
    "        corrected = conditions(corrected, indexes)\n",
    "    \n",
    "    fin = sentence_sentence_similarity(corrected)\n",
    "    if len(fin) != 0:\n",
    "        return fin\n",
    "    else:\n",
    "        return corrected\n",
    "\n",
    "\n",
    "\n",
    "print(correct_mod(['My', 'Mum', 'goe', 'out', 'some_times']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 7 (5 Marks):**\n",
    "\n",
    "Repeat the evaluation (as in Task 5) of your new algorithm and show that it outperforms the algorithm from Task 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation:\n",
    "\n",
    "From all above mentioned implementation ideas, it is observed that the accuracy has been increased to approximately 92%. Which is 10% increase from Task 3 and Task 4. Moreover, I have also cross checked for different test and train split and repeated the process and noted down the accuracy. It is observed the accuracy is between [89% to 93%].\n",
    "\n",
    "<b>Note:</b> Actual and Predicted sentence can be displayed by uncommenting the below print statement.\n",
    "\n",
    "*****************************************************\n",
    "### Results\n",
    "Average Accuracy of words in each sentence:  91.0187 % .\n",
    "\n",
    "42 out of 100 sentences predicted correctly without any error.\n",
    "\n",
    "Elapsed Time is:  212.06087279319763.\n",
    "*****************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [03:29<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************EVALUATION**********************************************************\n",
      "Average Accuracy of words in each sentence:  91.0187 %\n",
      "42 out of 100 sentences predicted correctly without any error\n",
      "Elapsed Time is:  209.64779901504517\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "def accuracy(actual_sent, sent_pred):\n",
    "    \"\"\"This is based on word to word accuracy calculation. Compares each word with the actual word and calculate accuracy\"\"\"\n",
    "    actual = actual_sent\n",
    "    predict = correct_mod(sent_pred)\n",
    "    # If the blank sentence i.e for a blank line predicted is also blank take accuracy as 1\n",
    "    if len(actual) == 0 and len(predict)==0:\n",
    "        accuracy = 1.0\n",
    "    else:\n",
    "        # Take all predicted words same as actual word and divide by lenght of sentence\n",
    "        accuracy = len(set(predict) & set(actual))/len(set(actual))\n",
    "    \n",
    "    #print(\"Actual Sentence: \", actual)\n",
    "    #print(\"Sentence to predict: \", sent_pred)\n",
    "    #print(\"Predicted Sentence: \", predict)\n",
    "    #print(\"Accuracy: \", accuracy)\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "acc = []\n",
    "for i in tqdm(range(len(test_corrected))):\n",
    "    acc.append(accuracy(test_corrected[i], test_original[i]))\n",
    "\n",
    "print(\"************************************************EVALUATION**********************************************************\")\n",
    "print(\"Average Accuracy of words in each sentence: \", round(sum(acc)/len(acc)*100, 4), \"%\")\n",
    "print(acc.count(1), \"out of 100 sentences predicted correctly without any error\")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed Time is: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
